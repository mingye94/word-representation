{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lingo-mit/6864-hw1/blob/master/6864_hw1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FU7xWiY6TyWS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into '6864-hw1'...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit \n",
    "rm -rf 6864-hw1\n",
    "git clone https://github.com/lingo-mit/6864-hw1.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A0MHaHrdUACZ"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/content/6864-hw1\")\n",
    "\n",
    "import csv\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "import lab_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cZ3MUj4iUf76"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you'll explore three different ways of using unlabeled text data to learn pretrained word representations. Your lab report will describe the effects of different modeling decisions (representation learning objective, context size, etc.) on both qualitative properties of learned representations and their effect on a downstream prediction problem.\n",
    "\n",
    "**General lab report guidelines**\n",
    "\n",
    "Homework assignments should be submitted in the form of a research report. (We'll be providing a place to upload them before the due date, but are still sorting out some logistics.) Please upload PDFs, with a maximum of four single-spaced pages. (If you want you can use the [Association for Computational Linguistics style files](http://acl2020.org/downloads/acl2020-templates.zip).) Reports should have one section for each part of the homework assignment below. Each section should describe the details of your code implementation, and include whatever charts / tables are necessary to answer the set of questions at the end of the corresponding homework part.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gG654Y9J3yHw"
   },
   "source": [
    "\n",
    "We're going to be working with a dataset of product reviews. It looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JwiX-Tc9V1xI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review: I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.\n",
      "rating: 1 (good)\n",
      "\n",
      "review: Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".\n",
      "rating: 0 (bad)\n",
      "\n",
      "review: This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch.\n",
      "rating: 1 (good)\n",
      "\n",
      "review: If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The flavor is very medicinal.\n",
      "rating: 0 (bad)\n",
      "\n",
      "review: Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.\n",
      "rating: 1 (good)\n",
      "\n",
      "review: I got a wild hair for taffy and ordered this five pound bag. The taffy was all very enjoyable with many flavors: watermelon, root beer, melon, peppermint, grape, etc. My only complaint is there was a bit too much red/black licorice-flavored pieces (just not my particular favorites). Between me, my kids, and my husband, this lasted only two weeks! I would recommend this brand of taffy -- it was a delightful treat.\n",
      "rating: 1 (good)\n",
      "\n",
      "Read 4000 total reviews.\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "n_positive = 0\n",
    "n_disp = 0\n",
    "with open(\"reviews.csv\") as reader:\n",
    "  csvreader = csv.reader(reader)\n",
    "  next(csvreader)\n",
    "  for id, review, label in csvreader:\n",
    "    label = int(label)\n",
    "\n",
    "    # hacky class balancing\n",
    "    if label == 1:\n",
    "      if n_positive == 2000:\n",
    "        continue\n",
    "      n_positive += 1\n",
    "    if len(data) == 4000:\n",
    "      break\n",
    "\n",
    "    data.append((review, label))\n",
    "    \n",
    "    if n_disp > 5:\n",
    "      continue\n",
    "    n_disp += 1\n",
    "    print(\"review:\", review)\n",
    "    print(\"rating:\", label, \"(good)\" if label == 1 else \"(bad)\")\n",
    "    print()\n",
    "\n",
    "print(f\"Read {len(data)} total reviews.\")\n",
    "np.random.shuffle(data)\n",
    "reviews, labels = zip(*data)\n",
    "train_reviews = reviews[:3000]\n",
    "train_labels = labels[:3000]\n",
    "val_reviews = reviews[3000:3500]\n",
    "val_labels = labels[3000:3500]\n",
    "test_reviews = reviews[3500:]\n",
    "test_labels = labels[3500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8h4k40QoXFO5"
   },
   "source": [
    "We've provided a little bit of helper code for reading in the dataset; your job is to implement the learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "twLHWqM6Z5xD"
   },
   "source": [
    "## Part 1: word representations via matrix factorization\n",
    "\n",
    "First, we'll construct the term--document matrix (look at `/content/6864-hw1/lab_util.py` in the file browser on the left if you want to see how this works)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3WPt6Y7-Z_7P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TD matrix is 2006 x 3000\n"
     ]
    }
   ],
   "source": [
    "vectorizer = lab_util.CountVectorizer()\n",
    "vectorizer.fit(train_reviews)\n",
    "td_matrix = vectorizer.transform(train_reviews).T\n",
    "print(f\"TD matrix is {td_matrix.shape[0]} x {td_matrix.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hd3-pw4XbD4B"
   },
   "source": [
    "First, implement a function that computes word representations via latent semantic analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KASVs8KubeBE"
   },
   "outputs": [],
   "source": [
    "def learn_reps_lsa(matrix, rep_size):\n",
    "  # `matrix` is a `|V| x n` matrix, where `|V|` is the number of words in the\n",
    "  # vocabulary. This function should return a `|V| x rep_size` matrix with each\n",
    "  # row corresponding to a word representation. The `sklearn.decomposition` \n",
    "  # package may be useful.\n",
    "\n",
    "  # Your code here!\n",
    "  from sklearn.decomposition import TruncatedSVD\n",
    "  result = TruncatedSVD(rep_size)\n",
    "  U_sigma = result.fit_transform(matrix)\n",
    "#  word_rep = np.matmul((np.matmul(U_mat, Sig_mat)), V_mat)\n",
    "  word_rep = np.matmul(U_sigma, np.linalg.inv(np.diag(result.singular_values_)))\n",
    "  return word_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKWzRC0dclVK"
   },
   "source": [
    "Let's look at some representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ad7RZkwceWw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good 47\n",
      "  gerber 1.876\n",
      "  crazy 1.885\n",
      "  luck 1.887\n",
      "  beat 1.907\n",
      "  suspect 1.907\n",
      "bad 201\n",
      "  disgusting 1.624\n",
      "  gone 1.772\n",
      "  horrible 1.772\n",
      "  positive 1.778\n",
      "  shortbread 1.783\n",
      "cookie 504\n",
      "  nana's 0.946\n",
      "  bars 1.392\n",
      "  odd 1.445\n",
      "  wants 1.463\n",
      "  cookies 1.479\n",
      "jelly 351\n",
      "  cardboard 1.194\n",
      "  twist 1.196\n",
      "  advertised 1.329\n",
      "  peanuts 1.356\n",
      "  plastic 1.503\n",
      "dog 925\n",
      "  happier 1.667\n",
      "  earlier 1.691\n",
      "  eats 1.710\n",
      "  standard 1.730\n",
      "  stays 1.734\n",
      "the 36\n",
      "  suspect 1.950\n",
      "  flowers 1.966\n",
      "  leaked 1.968\n",
      "  burn 1.969\n",
      "  m 1.969\n",
      "3 289\n",
      "  omega 1.756\n",
      "  vendor 1.768\n",
      "  supermarket 1.777\n",
      "  nutty 1.778\n",
      "  facts 1.794\n"
     ]
    }
   ],
   "source": [
    "reps = learn_reps_lsa(td_matrix, 500)\n",
    "words = [\"good\", \"bad\", \"cookie\", \"jelly\", \"dog\", \"the\", \"3\"]\n",
    "show_tokens = [vectorizer.tokenizer.word_to_token[word] for word in words]\n",
    "lab_util.show_similar_words(vectorizer.tokenizer, reps, show_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LsOAGLB3iRjT"
   },
   "source": [
    "We've been operating on the raw count matrix, but in class we discussed several reweighting schemes aimed at making LSA representations more informative. \n",
    "\n",
    "Here, implement the TF-IDF transform and see how it affects learned representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1y3PmW-IgpqA"
   },
   "outputs": [],
   "source": [
    "def transform_tfidf(matrix):\n",
    "  # `matrix` is a `|V| x |D|` matrix of raw counts, where `|V|` is the \n",
    "  # vocabulary size and `|D|` is the number of documents in the corpus. This\n",
    "  # function should (nondestructively) return a version of `matrix` with the\n",
    "  # TF-IDF transform appliied.\n",
    "\n",
    "  # Your code here!\n",
    "  V = np.size(matrix, 0)\n",
    "  D = np.size(matrix, 1)\n",
    "  result = np.zeros((V, D))\n",
    "  \n",
    "  non_zero = np.count_nonzero(matrix, axis = 1)\n",
    "  doc_word = np.sum(matrix, axis = 0)\n",
    "                  \n",
    "  for i in range(V):\n",
    "      for j in range(D):\n",
    "          if non_zero[i] == 0:\n",
    "              result[i,j] = 0\n",
    "          else:\n",
    "              result[i,j] = matrix[i,j]/doc_word[j]*np.log(D/non_zero[i])\n",
    "    \n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xOprgqzHi7bk"
   },
   "source": [
    "How does this change the learned similarity function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SV5xKLYTi7LA",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good 47\n",
      "  required 1.742\n",
      "  sample 1.766\n",
      "  lays 1.790\n",
      "  suspect 1.805\n",
      "  customers 1.808\n",
      "bad 201\n",
      "  death 1.374\n",
      "  classic 1.546\n",
      "  positive 1.577\n",
      "  ate 1.590\n",
      "  floor 1.594\n",
      "cookie 504\n",
      "  nana's 1.061\n",
      "  shape 1.335\n",
      "  bars 1.484\n",
      "  likely 1.518\n",
      "  keeps 1.545\n",
      "jelly 351\n",
      "  shocked 1.292\n",
      "  plum 1.300\n",
      "  beans 1.306\n",
      "  anyone 1.351\n",
      "  softer 1.363\n",
      "dog 925\n",
      "  required 1.270\n",
      "  lamb 1.608\n",
      "  pets 1.620\n",
      "  ball 1.638\n",
      "  animals 1.673\n",
      "the 36\n",
      "  <unk> 1.433\n",
      "  and 1.492\n",
      "  of 1.561\n",
      "  bottom 1.563\n",
      "  best 1.604\n",
      "3 289\n",
      "  earlier 1.426\n",
      "  serious 1.457\n",
      "  omega 1.504\n",
      "  pricing 1.550\n",
      "  includes 1.559\n",
      "good 47\n",
      "  crazy 1.640\n",
      "  flaxseed 1.723\n",
      "  suspect 1.734\n",
      "  pretty 1.746\n",
      "  bread 1.747\n",
      "bad 201\n",
      "  awful 1.273\n",
      "  huge 1.313\n",
      "  smells 1.328\n",
      "  disgusting 1.359\n",
      "  minutes 1.443\n",
      "cookie 504\n",
      "  cookies 0.499\n",
      "  nana's 0.581\n",
      "  oreos 1.051\n",
      "  bites 1.159\n",
      "  bars 1.283\n",
      "jelly 351\n",
      "  twist 1.166\n",
      "  creamer 1.259\n",
      "  refund 1.398\n",
      "  cardboard 1.400\n",
      "  shipped 1.412\n",
      "dog 925\n",
      "  foods 1.107\n",
      "  stays 1.147\n",
      "  switched 1.248\n",
      "  appeal 1.269\n",
      "  pet 1.280\n",
      "the 36\n",
      "  suspect 1.878\n",
      "  kona 1.884\n",
      "  future 1.893\n",
      "  idea 1.899\n",
      "  rest 1.899\n",
      "3 289\n",
      "  8 1.393\n",
      "  beat 1.403\n",
      "  nutty 1.449\n",
      "  closer 1.449\n",
      "  vendor 1.449\n",
      "good 47\n",
      "  gerber 1.876\n",
      "  crazy 1.885\n",
      "  luck 1.887\n",
      "  beat 1.907\n",
      "  suspect 1.907\n",
      "bad 201\n",
      "  disgusting 1.624\n",
      "  gone 1.772\n",
      "  horrible 1.772\n",
      "  positive 1.778\n",
      "  shortbread 1.783\n",
      "cookie 504\n",
      "  nana's 0.946\n",
      "  bars 1.392\n",
      "  odd 1.445\n",
      "  wants 1.463\n",
      "  cookies 1.479\n",
      "jelly 351\n",
      "  cardboard 1.194\n",
      "  twist 1.196\n",
      "  advertised 1.329\n",
      "  peanuts 1.356\n",
      "  plastic 1.503\n",
      "dog 925\n",
      "  happier 1.667\n",
      "  earlier 1.691\n",
      "  eats 1.710\n",
      "  standard 1.730\n",
      "  stays 1.734\n",
      "the 36\n",
      "  suspect 1.950\n",
      "  flowers 1.966\n",
      "  leaked 1.968\n",
      "  burn 1.969\n",
      "  m 1.969\n",
      "3 289\n",
      "  omega 1.756\n",
      "  vendor 1.768\n",
      "  supermarket 1.777\n",
      "  nutty 1.778\n",
      "  facts 1.794\n"
     ]
    }
   ],
   "source": [
    "Wtt = td_matrix.dot(td_matrix.T)\n",
    "td_matrix_tfidf = transform_tfidf(td_matrix)\n",
    "reps_tfidf = learn_reps_lsa(td_matrix_tfidf, 500)\n",
    "reps_Wtt = learn_reps_lsa(Wtt, 200)\n",
    "lab_util.show_similar_words(vectorizer.tokenizer, reps_tfidf, show_tokens)\n",
    "lab_util.show_similar_words(vectorizer.tokenizer, reps_Wtt, show_tokens)\n",
    "lab_util.show_similar_words(vectorizer.tokenizer, reps, show_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HO-NG4u1kG9z"
   },
   "source": [
    "Now that we have some representations, let's see if we can do something useful with them.\n",
    "\n",
    "Below, implement a feature function that represents a document as the sum of its\n",
    "learned word embeddings.\n",
    "\n",
    "The remaining code trains a logistic regression model on a set of *labeled* reviews; we're interested in seeing how much representations learned from *unlabeled* reviews improve classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6B08xvIFlee3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word features, 10 examples\n",
      "------------ Train ------------\n",
      "(10, 2006)\n",
      "------------ Eval ------------\n",
      "(500, 2006)\n",
      "test accuracy 0.496\n",
      "\n",
      "lsa features, 10 examples\n",
      "------------ Train ------------\n",
      "(10, 2006)\n",
      "------------ Eval ------------\n",
      "(500, 2006)\n",
      "test accuracy 0.49\n",
      "\n",
      "combo features, 10 examples\n",
      "------------ Train ------------\n",
      "(10, 2006)\n",
      "------------ Eval ------------\n",
      "(500, 2006)\n",
      "test accuracy 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def word_featurizer(xs):\n",
    "  # normalize\n",
    "  return xs / np.sqrt((xs ** 2).sum(axis=1, keepdims=True))\n",
    "\n",
    "def lsa_featurizer(xs):\n",
    "  # This function takes in a matrix in which each row contains the word counts\n",
    "  # for the given review. It should return a matrix in which each row contains\n",
    "  # the learned feature representation of each review (e.g. the sum of LSA \n",
    "  # word representations).\n",
    "  \n",
    "  feats = None # Your code here!\n",
    "  #transformed_mat = transform_tfidf(td_matrix)\n",
    "\n",
    "  #feats = transform_tfidf(xs)\n",
    "  #print(transformed_mat.shape)\n",
    "  #print(transformed_mat1.shape)\n",
    "  #word_rep = learn_reps_lsa(transformed_mat, 100)\n",
    "  #print(word_rep)\n",
    "  #print(word_rep1)\n",
    "  #feats = np.transpose(td_matrix).dot(transformed_mat)\n",
    "  feats = xs.dot(reps_tfidf)\n",
    "  # normalize\n",
    "  return feats / np.sqrt((feats ** 2).sum(axis=1, keepdims=True))\n",
    "\n",
    "def combo_featurizer(xs):\n",
    "  return np.concatenate((word_featurizer(xs), lsa_featurizer(xs)), axis=1)\n",
    "\n",
    "def train_model(featurizer, xs, ys):\n",
    "  import sklearn.linear_model\n",
    "  xs_featurized = featurizer(xs)\n",
    "  model = sklearn.linear_model.LogisticRegression()\n",
    "  model.fit(xs_featurized, ys)\n",
    "  return model\n",
    "\n",
    "def eval_model(model, featurizer, xs, ys):\n",
    "  xs_featurized = featurizer(xs)\n",
    "  pred_ys = model.predict(xs_featurized)\n",
    "  print(\"test accuracy\", np.mean(pred_ys == ys))\n",
    "\n",
    "def training_experiment(name, featurizer, n_train):\n",
    "  print(f\"{name} features, {n_train} examples\")\n",
    "  train_xs = vectorizer.transform(train_reviews[:n_train])\n",
    "  train_ys = train_labels[:n_train]\n",
    "  test_xs = vectorizer.transform(test_reviews)\n",
    "  test_ys = test_labels\n",
    "  print('------------ Train ------------')\n",
    "  print(train_xs.shape)\n",
    "  model = train_model(featurizer, train_xs, train_ys)\n",
    "  print('------------ Eval ------------')\n",
    "  print(test_xs.shape)\n",
    "  eval_model(model, featurizer, test_xs, test_ys)\n",
    "  print()\n",
    "\n",
    "training_experiment(\"word\", word_featurizer, 10)\n",
    "training_experiment(\"lsa\", lsa_featurizer, 10)\n",
    "training_experiment(\"combo\", combo_featurizer, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rpXziVNrlfp2"
   },
   "source": [
    "**Part 1: Lab writeup**\n",
    "\n",
    "Part 1 of your lab report should discuss any implementation details that were important to filling out the code above. Then, use the code to set up experiments that answer the following questions:\n",
    "\n",
    "1. Qualitatively, what do you observe about nearest neighbors in representation    space? (E.g. what words are most similar to _the_, _dog_, _3_, and _good_?)\n",
    "\n",
    "2. How does the size of the LSA representation affect this behavior?\n",
    "\n",
    "\n",
    "3. Recall that the we can compute the word co-occurrence matrix $W_{tt} = W_    \n",
    "   {td} W_{td}^\\top$. What can you prove about the relationship between the    \n",
    "   left singular vectors of $W_{td}$ and $W_{tt}$? Do you observe this behavior \n",
    "   with your implementation of `learn_reps_lsa`? Why or why not?\n",
    "\n",
    "4. Do learned representations help with the review classification problem? What\n",
    "   is the relationship between the number of labeled examples and the effect of\n",
    "   word embeddings?\n",
    "   \n",
    "5. What is the relationship between the size of the word embeddings and their      usefulness for the classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AxfunCYh5nmZ"
   },
   "source": [
    "## Part 2: word representations via language modeling\n",
    "\n",
    "In this section, we'll train a word embedding model with a word2vec-style objective rather than a matrix factorization objective. This requires a little more work; we've provided scaffolding for a PyTorch model implementation below.\n",
    "(If you've never used PyTorch before, there are some tutorials [here](https://pytorch.org/tutorials/). You're also welcome to implement these experiments in\n",
    "any other framework of your choosing.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M1napibQ6aub"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as torch_data\n",
    "\n",
    "class Word2VecModel(nn.Module):\n",
    "  # A torch module implementing a word2vec predictor. The `forward` function\n",
    "  # should take a batch of context word ids as input and predict the word \n",
    "  # in the middle of the context as output, as in the CBOW model from lecture.\n",
    "\n",
    "  def __init__(self, vocab_size, embed_dim):\n",
    "      super().__init__()\n",
    "      # Your code here!\n",
    "      self.voc_num = vocab_size\n",
    "      self.emb_dim = embed_dim\n",
    "      self.word_embed = nn.Embedding (vocab_size, embed_dim)\n",
    "      self.weight1 = nn.Linear(embed_dim, vocab_size)\n",
    "      #self.act_fn1 = nn.relu()\n",
    "      #self.weight2 = nn.Linear(100, vocab_size)\n",
    "        \n",
    "  def forward(self, context):\n",
    "      # Context is an `n_batch x n_context` matrix of integer word ids\n",
    "      # this function should return a set of scores for predicting the word \n",
    "      # in the middle of the context\n",
    "\n",
    "      # Your code here!\n",
    "      #print(type(context))\n",
    "      #ave_context = torch.sum(context, dim=1)\n",
    "      #print(ave_context)\n",
    "      sum_rep = self.word_embed(context).sum(dim = 1)/context.shape[1]\n",
    "      #print(list(sum_rep.size()))\n",
    "      #print(sum_rep)\n",
    "      #hidden = self.weight1(sum_rep)\n",
    "      #hidden = F.relu(hidden)\n",
    "      #sum_rep = sum_rep/np.size(context, 1)\n",
    "      #average#\n",
    "      out_rep = self.weight1(sum_rep)\n",
    "      score = F.log_softmax(out_rep, dim = 1)\n",
    "      return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ePgZlityuWr3"
   },
   "outputs": [],
   "source": [
    "def learn_reps_word2vec(corpus, window_size, rep_size, n_epochs, n_batch):\n",
    "  # This method takes in a corpus of training sentences. It returns a matrix of\n",
    "  # word embeddings with the same structure as used in the previous section of \n",
    "  # the assignment. (You can extract this matrix from the parameters of the \n",
    "  # Word2VecModel.)\n",
    "\n",
    "  tokenizer = lab_util.Tokenizer()\n",
    "  tokenizer.fit(corpus)\n",
    "  tokenized_corpus = tokenizer.tokenize(corpus)\n",
    "\n",
    "  ngrams = lab_util.get_ngrams(tokenized_corpus, window_size)\n",
    "\n",
    "  device = torch.device('cpu')  # run on colab gpu\n",
    "  model = Word2VecModel(tokenizer.vocab_size, rep_size).to(device)\n",
    "  optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "  loss_fn = nn.NLLLoss() # Your code here\n",
    "\n",
    "  loader = torch_data.DataLoader(ngrams, batch_size=n_batch, shuffle=True)\n",
    "\n",
    "  for epoch in range(n_epochs):\n",
    "    for context, label in loader:\n",
    "      # as described above, `context` is a batch of context word ids, and\n",
    "      # `label` is a batch of predicted word labels\n",
    "      # Your code here!\n",
    "      model.zero_grad()\n",
    "      pred = model(context)\n",
    "      loss = loss_fn(pred, label)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "  # reminder: you want to return a `vocab_size x embedding_size` numpy array\n",
    "  # Your code here!\n",
    "  return model.word_embed.weight.data\n",
    "  #return model.weight1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aaUy1cNuB3W1"
   },
   "outputs": [],
   "source": [
    "reps_word2vec = learn_reps_word2vec(train_reviews, 1, 500, 10, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O3oE-tpR7I39"
   },
   "source": [
    "After training the embeddings, we can try to visualize the embedding space to see if it makes sense. First, we can take any word in the space and check its closest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yMW4QND56bHF",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good 47\n",
      "  superior 1.687\n",
      "  nutritious 1.690\n",
      "  doing 1.691\n",
      "  hole 1.696\n",
      "  part 1.706\n",
      "bad 201\n",
      "  sugary 1.680\n",
      "  tart 1.712\n",
      "  wide 1.720\n",
      "  liquid 1.722\n",
      "  bottom 1.723\n",
      "cookie 504\n",
      "  exact 1.679\n",
      "  beyond 1.713\n",
      "  satisfying 1.720\n",
      "  0 1.723\n",
      "  nicely 1.728\n",
      "jelly 351\n",
      "  local 1.633\n",
      "  bears 1.662\n",
      "  junk 1.666\n",
      "  nutrition 1.668\n",
      "  egg 1.670\n",
      "dog 925\n",
      "  cat 1.594\n",
      "  acid 1.651\n",
      "  puppy 1.671\n",
      "  belgian 1.685\n",
      "  wrong 1.689\n",
      "the 36\n",
      "  their 1.540\n",
      "  our 1.540\n",
      "  my 1.668\n",
      "  every 1.715\n",
      "  a 1.725\n",
      "3 289\n",
      "  9 1.663\n",
      "  5 1.678\n",
      "  salsa 1.678\n",
      "  zero 1.693\n",
      "  40 1.694\n"
     ]
    }
   ],
   "source": [
    "lab_util.show_similar_words(vectorizer.tokenizer, reps_word2vec.numpy(), show_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ue-9CPSc7fi9"
   },
   "source": [
    "We can also cluster the embedding space. Clustering in 4 or more dimensions is hard to visualize, and even clustering in 2 or 3 can be difficult because there are so many words in the vocabulary. One thing we can try to do is assign cluster labels and qualitiatively look for an underlying pattern in the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v-Yf6NMCXVx4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: 0\n",
      "seeds: 0\n",
      "themselves: 1\n",
      "provide: 1\n",
      "work: 1\n",
      "close: 1\n",
      "bake: 1\n",
      "replace: 1\n",
      "feel: 1\n",
      "carbonated: 2\n",
      "what: 2\n",
      "pizza: 2\n",
      "stomach: 2\n",
      "science: 2\n",
      "delivery: 2\n",
      "plum: 2\n",
      "coconut: 2\n",
      "constantly: 2\n",
      "fact: 3\n",
      "list: 3\n",
      "holds: 3\n",
      "him: 3\n",
      "anywhere: 3\n",
      "service: 3\n",
      "bbq: 5\n",
      "greta: 5\n",
      "points: 5\n",
      "part: 5\n",
      "tassimo: 5\n",
      "toddler: 5\n",
      "traditional: 5\n",
      "candy: 5\n",
      "varieties: 5\n",
      "http: 5\n",
      "lot: 5\n",
      "result: 5\n",
      "seller: 5\n",
      "marinade: 5\n",
      "<unk>: 5\n",
      "suggested: 5\n",
      "party: 5\n",
      "needed: 6\n",
      "seems: 6\n",
      "would: 6\n",
      "might: 6\n",
      "followed: 6\n",
      "looked: 6\n",
      "lock: 6\n",
      "makes: 6\n",
      "tangy: 7\n",
      "awful: 7\n",
      "bold: 7\n",
      "china: 7\n",
      "rotten: 7\n",
      "black: 7\n",
      "great: 7\n",
      "little: 7\n",
      "natural: 7\n",
      "flavored: 7\n",
      "eater: 7\n",
      "almond: 7\n",
      "hot: 7\n",
      "granted: 7\n",
      "priced: 7\n",
      "terrific: 7\n",
      "health: 8\n",
      "15: 8\n",
      "literally: 8\n",
      "longer: 8\n",
      "stevia: 8\n",
      "this: 8\n",
      "acid: 8\n",
      "dead: 8\n",
      "most: 8\n",
      "wheat: 8\n",
      "finally: 8\n",
      "wild: 8\n",
      "kids: 8\n",
      "portion: 8\n",
      "clams: 8\n",
      "oats: 8\n",
      "otherwise: 8\n",
      "fence: 8\n",
      "perfectly: 8\n",
      "same: 8\n",
      "also: 8\n",
      "items: 8\n",
      "gummy: 8\n",
      "e: 8\n",
      "?: 9\n",
      "here: 9\n",
      "until: 9\n",
      "stock: 9\n",
      "advertised: 9\n",
      "careful: 9\n",
      "life: 9\n",
      "favorites: 9\n",
      "excited: 9\n",
      "comparable: 9\n",
      "chance: 9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "indices = KMeans(n_clusters=10).fit_predict(reps_word2vec)\n",
    "zipped = list(zip(range(vectorizer.tokenizer.vocab_size), indices))\n",
    "np.random.shuffle(zipped)\n",
    "zipped = zipped[:100]\n",
    "zipped = sorted(zipped, key=lambda x: x[1])\n",
    "for token, cluster_idx in zipped:\n",
    "  word = vectorizer.tokenizer.token_to_word[token]\n",
    "  print(f\"{word}: {cluster_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ci1TkENU78Wn"
   },
   "source": [
    "Finally, we can use the trained word embeddings to construct vector representations of full reviews. One common approach is to simply average all the word embeddings in the review to create an overall embedding. Implement the transform function in Word2VecFeaturizer to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A5vjmRV6Dgbu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec features, 3000 examples\n",
      "------------ Train ------------\n",
      "(3000, 2006)\n",
      "------------ Eval ------------\n",
      "(500, 2006)\n",
      "test accuracy 0.788\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def lsa_featurizer(xs):\n",
    "  feats = None # Your code here!\n",
    "  feats = xs.dot(reps_word2vec)\n",
    "  for i in range(np.size(xs, 0)):\n",
    "    feats[i,:] = feats[i,:]/(np.sum(xs, axis = 1)[i])\n",
    "  \n",
    "  # normalize\n",
    "  return feats / np.sqrt((feats ** 2).sum(axis=1, keepdims=True))\n",
    "\n",
    "training_experiment(\"word2vec\", lsa_featurizer, 3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XSfoQbxaXtfH"
   },
   "source": [
    "**Part 2: Lab writeup**\n",
    "\n",
    "Part 2 of your lab report should discuss any implementation details that were important to filling out the code above. Then, use the code to set up experiments that answer the following questions:\n",
    "\n",
    "1. Qualitatively, what do you observe about nearest neighbors in representation space? (E.g. what words are most similar to _the_, _dog_, _3_, and _good_?) How well do word2vec representations correspond to your intuitions about word similarity?\n",
    "\n",
    "2. One important parameter in word2vec-style models is context size. How does changing the context size affect the kinds of representations that are learned?\n",
    "\n",
    "3. How do results on the downstream classification problem compare to \n",
    "   part 1?\n",
    "\n",
    "4. What are some advantages and disadvantages of learned embedding representations, relative to the featurization done in part 1?\n",
    "\n",
    "5. What are some potential problems with constructing a representation of the review by averaging the embeddings of the individual words?"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "6864-hw1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (PyTorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
